{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f50cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# new import statements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33d56e",
   "metadata": {},
   "source": [
    "# ML overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b4253",
   "metadata": {},
   "source": [
    "#### Covid deaths analysis\n",
    "\n",
    "- Source: https://data.dhsgis.wi.gov/\n",
    "    - Specifically, let's analyze \"COVID-19 Data by Census Tract V2\": https://data.dhsgis.wi.gov/datasets/wi-dhs::covid-19-data-by-census-tract-v2/explore\n",
    "        - Status Flag Values: -999: Census tracts, municipalities, school districts, and zip codes with 0â€“4 aggregate counts for any data have been suppressed. County data with 0-4 aggregate counts by demographic factors (e.g., by age group, race, ethnicity) have been suppressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696eec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not reptitivitely download large datasets\n",
    "# Save a local copy instead\n",
    "dataset_file = \"covid.geojson\"\n",
    "if os.path.exists(dataset_file):\n",
    "    print(\"Reading local file.\")\n",
    "    df = gpd.read_file(dataset_file)\n",
    "else:\n",
    "    print(\"Downloading the dataset.\")\n",
    "    url = \"https://dhsgis.wi.gov/server/rest/services/DHS_COVID19/COVID19_WI_V2/MapServer/9/query?outFields=*&where=1%3D1&f=geojson\"\n",
    "    # Read the geojson data\n",
    "    \n",
    "    # Save it to a local file (dataset_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905da51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3434aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geographic plot\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e73632",
   "metadata": {},
   "source": [
    "### Predicting \"DTH_CUM_CP\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cebffa",
   "metadata": {},
   "source": [
    "### How can we get a clean dataset of COVID deaths in WI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -999 with 2; 2 is between 0-4; random choice instead of using 0\n",
    "df = \n",
    "# we must communicate in final results what percent of values were guessed (imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff709d",
   "metadata": {},
   "source": [
    "How would we know if the data is now clean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot to visualize relationship between \"POP\" and \"DTH_CUM_CP\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073a940",
   "metadata": {},
   "source": [
    "Which points are concerning? Let's take a closer look.\n",
    "\n",
    "#### Which rows have \"DTH_CUM_CP\" greater than 300?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DTH_CUM_CP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377143e",
   "metadata": {},
   "source": [
    "#### Valid rows have \"GEOID\" that only contains digits\n",
    "\n",
    "Using `str` methods to perform filtering: `str.fullmatch` does a full string match given a reg-ex. Because it does full string match anchor characters (`^`, `$`) won't be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529781db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GEOID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d583d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"GEOID\"].str.fullmatch(r\"\\d+\")]\n",
    "df.plot.scatter(x=\"POP\", y=\"DTH_CUM_CP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be50600",
   "metadata": {},
   "source": [
    "### How can we train/fit models to known data to predict unknowns?\n",
    "- Feature(s) => Predictions\n",
    "    - Population => Deaths\n",
    "    - Cases => Deaths\n",
    "    - Cases by Age => Deaths\n",
    "    \n",
    "- General structure for fitting models:\n",
    "    ```python\n",
    "    model = <some model>\n",
    "    model.fit(X, y)\n",
    "    y = model.predict(X)\n",
    "    ```\n",
    "    - where `X` needs to be a matrix or a `DataFrame` and `y` needs to be an array (vector) or a `Series`\n",
    "    - after fitting, `model` object instance stores the information about relationship between features (x values) and predictions (y values)\n",
    "    - `predict` returns a `numpy` array, which can be treated like a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e65c3",
   "metadata": {},
   "source": [
    "### Predicting \"DTH_CUM_CP\" using \"POP\" as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdbba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must specify a list of columns to make sure we extract a DataFrame and not a Series\n",
    "# Feature DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aad05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Series: \"DTH_CUM_CP\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d6831",
   "metadata": {},
   "source": [
    "### Let's use `LinearRegression` model.\n",
    "\n",
    "- `from sklearn.linear_model import LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols = \n",
    "ycol = \n",
    "\n",
    "model = \n",
    "model\n",
    "# less interesting because we are predicting what we already know\n",
    "y = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e589d923",
   "metadata": {},
   "source": [
    "Predicting for new values of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame({\"POP\": [1000, 2000, 3000]})\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a new column called \"predicted deaths\" with the predictions\n",
    "predict_df[\"predicted deaths\"] = model.predict(predict_df)\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c649201",
   "metadata": {},
   "source": [
    "### How can we visualize model predictions?\n",
    "\n",
    "- Let's predict deaths for \"POP\" ranges like 0, 1000, 2000, ..., 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame({\"POP\": range(0, 20000, 1000)})\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a new column called \"predicted deaths\" with the predictions\n",
    "predict_df[\"predicted deaths\"] = model.predict(predict_df)\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot to visualize relationship between \"POP\" and \"predicted deaths\"\n",
    "ax = predict_df.plot.line(x=\"POP\", y=\"predicted deaths\", color=\"r\")\n",
    "# Create a scatter plot to visualize relationship between \"POP\" and \"DTH_CUM_CP\"\n",
    "df.plot.scatter(x=\"POP\", y=\"DTH_CUM_CP\", ax=ax, color=\"k\", alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2d3f8",
   "metadata": {},
   "source": [
    "### How can we get a formula for the relationship?\n",
    "\n",
    "- `y=mx+c`, where `y` is our predictions and `x` are the features used for the fit\n",
    "    - Slope of the line (`m`) given by `model.coef_[0]`\n",
    "    - Intercept of the line (`c`) given by `model.intercept_`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d19b3",
   "metadata": {},
   "source": [
    "Model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope of the line\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32690085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept of the line\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"deaths ~= {round(model.coef_[0], 4)} * population + {round(model.intercept_, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ccba5",
   "metadata": {},
   "source": [
    "### How well does our model fit the data?\n",
    "- explained variance score\n",
    "- R^2 (\"r squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4af81",
   "metadata": {},
   "source": [
    "#### `sklearn.metrics.explained_variance_score(y_true, y_pred)`\n",
    "- requires `import sklearn`\n",
    "- calculates the explained variance score given:\n",
    "    - y_true: actual death values in our example\n",
    "    - y_pred: prediction of deaths in our example\n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols, ycol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now make predictions for the known data\n",
    "predictions = model\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dadb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.explained_variance_score(, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd81950",
   "metadata": {},
   "source": [
    "#### Explained variance score\n",
    "\n",
    "- `explained_variance = (known_var - explained_variance) / known_var`\n",
    "    - where `known_var = y_true.var()` and `explained_variance = (y_true - y_pred).var()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc3bb5",
   "metadata": {},
   "source": [
    "What is the variation in known deaths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute variance of \"DTH_CUM_CP\" column\n",
    "known_var = df[ycol]\n",
    "known_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained_variance\n",
    "explained_variance = (df[ycol] - predictions).var()   \n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb076b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained_variance score\n",
    "explained_variance_score = (known_var - explained_variance) / known_var\n",
    "explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a55a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison here is the explained variance score from sklearn\n",
    "sklearn.metrics.explained_variance_score(df[ycol], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547452da",
   "metadata": {},
   "source": [
    "#### `sklearn.metrics.r2_score(y_true, y_pred)`\n",
    "\n",
    "- requires `import sklearn`\n",
    "- calculates the explained variance score given:\n",
    "    - y_true: actual death values in our example\n",
    "    - y_pred: prediction of deaths in our example\n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ba67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(df[ycol], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e60fed7",
   "metadata": {},
   "source": [
    "#### R^2 score (aka coefficient of determination) approximation\n",
    "\n",
    "- `r2_score = (known_var - r2_val) / known_var`\n",
    "    - where `known_var = y_true.var()` and `r2_val = ((y_true - y_pred) ** 2).mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ea427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_val\n",
    "r2_val = ((df[ycol] - predictions) ** 2).mean()\n",
    "r2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = (known_var - r2_val) / known_var\n",
    "r2_score # there might be minor rounding off differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc33af9",
   "metadata": {},
   "source": [
    "#### `model.score(X, y)`\n",
    "- invokes `predict` method for calculating predictions (`y`) based on features (`X`) and compares the predictions with true values of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bde089",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1768f9a9",
   "metadata": {},
   "source": [
    "#### Did our model learn, or just memorize (that is, \"overfit\")?\n",
    "\n",
    "- Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a77fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two equal parts\n",
    "len(df) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual way of splitting train and test data\n",
    "train, test = df.iloc[:len(df)//2], df.iloc[len(df)//2:]\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f45dd74",
   "metadata": {},
   "source": [
    "Problem with manual splitting is, we need to make sure that the data is not sorted in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a781391",
   "metadata": {},
   "source": [
    "#### `train_test_split(<dataframe>, test_size=<val>)`\n",
    "\n",
    "- requires `from sklearn.model_selection import train_test_split`\n",
    "- shuffles the data and then splits based on 75%-25% split between train and test\n",
    "    - produces new train and test data every single time\n",
    "- `test_size` parameter can take two kind of values:\n",
    "    - actual number of rows that we want in test data\n",
    "    - fractional number representing the ratio of train versus test data\n",
    "    - default value is `0.25`\n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test size using row count\n",
    "train, test = train_test_split(df, test_size=120)\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test size using fraction\n",
    "train, test = train_test_split(df, test_size=0.5)\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell twice will give you two different train datasets\n",
    "train, test = train_test_split(df)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe05a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df)\n",
    "\n",
    "# Let's use the train and the test data\n",
    "model = LinearRegression()\n",
    "# Fit using training data\n",
    "model.fit(, )\n",
    "# Predict using test data\n",
    "y = model.predict()\n",
    "# We can use score directly as it automatically invokes predict\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0e21b",
   "metadata": {},
   "source": [
    "Running the above cell again will give you entirely different model and score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b1c50",
   "metadata": {},
   "source": [
    "#### How can we minimize noise due to random train/test splits?\n",
    "\n",
    "### Cross validation: `cross_val_score(estimator, X, y)`\n",
    "\n",
    "- requires `from sklearn.model_selection import cross_val_score`\n",
    "-  do many different train/test splits of the values, fitting and scoring the model across each combination\n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa17fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df)\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean of the scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9d4d4",
   "metadata": {},
   "source": [
    "#### How can we compare models?\n",
    "- model 1: POP => DEATHS\n",
    "- model 2: CASES (POS_CUM_CP) => DEATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = LinearRegression()\n",
    "model1_scores = cross_val_score(model1, )\n",
    "model2_scores = cross_val_score(model2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3070bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced0919",
   "metadata": {},
   "source": [
    "Which of these two models do you think will perform better? Probably model2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfedd8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.Series({\"model1\": model1_scores.mean(),\n",
    "                   \"model2\": model2_scores.mean()})\n",
    "means.plot.bar(figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312aa001",
   "metadata": {},
   "source": [
    "How do we know the above difference is not noise? Let's calculate standard deviation and display error bars on the bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = pd.Series({\"model1\": model1_scores.std(),\n",
    "                 \"model2\": model2_scores.std()})\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error bar by passing argument to paramenter yerr\n",
    "means.plot.bar(figsize=(3, 3), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b68db6",
   "metadata": {},
   "source": [
    "Pick a winner and run it one more time against test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5bce9",
   "metadata": {},
   "source": [
    "#### How can we use multiple x variables (multiple regression)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "xcols = ['POS_0_9_CP', 'POS_10_19_CP', 'POS_20_29_CP', 'POS_30_39_CP',\n",
    "       'POS_40_49_CP', 'POS_50_59_CP', 'POS_60_69_CP', 'POS_70_79_CP',\n",
    "       'POS_80_89_CP', 'POS_90_CP']\n",
    "ycol = \"DTH_CUM_CP\"\n",
    "\n",
    "model.fit(train[xcols], train[ycol])\n",
    "model.score(test[xcols], test[ycol]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4c272",
   "metadata": {},
   "source": [
    "#### How can we interpret what features the model is relying on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.coef_).plot.bar(figsize=(3, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
