{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x = np.random.uniform(0.1,5,100)\n",
    "noise = np.random.normal(scale=0.3, size=x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition: factorization\n",
    "Why is it useful to express something as a few parts multiplied together?\n",
    "To convey more information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at what points does y=0?\n",
    "# y = -x**3 + 7*x**2 - 14*x + 8\n",
    "y = (4-x) * (2-x) * (1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"x\": x, \"y\": y+noise}).plot.scatter(x=\"x\", y=\"y\")\n",
    "plt.hlines(0, -1, 6, color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some cool dimensionality reduction examples:\n",
    "https://pair-code.github.io/understanding-umap/ \\\n",
    "https://distill.pub/2016/misread-tsne/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition with Principal Component Analysis (PCA)\n",
    "Q: Is it possible to use fewer columns to represent this dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(make_blobs(centers=2, random_state=320)[0], columns=[\"A\", \"B\"])\n",
    "df[\"C\"] = df[\"A\"] * 2\n",
    "df[\"D\"] = df[\"A\"] - df[\"B\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Yes. C is two times of A and D is A - B, so we only need A & B and their relationship to C & D to represent the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot A & B column\n",
    "df.plot.scatter(\"A\", \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.decomposition.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCA()\n",
    "W = p.fit_transform(df[[\"A\", \"B\"]])\n",
    "C = p.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA will first find the mean\n",
    "mean_point = p.mean_\n",
    "mean_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"A\", \"B\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean point\n",
    "df.plot.scatter(\"A\", \"B\")\n",
    "plt.plot(mean_point[0], mean_point[1], marker=\"X\", markersize=20, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is called the **component matrix** \\\n",
    "first row of C is the most important component \\\n",
    "second row of C is the second most important component \\\n",
    "and so on ...\n",
    "\n",
    "Each row is in the form of the slope of the componenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two components for 2d data\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first component, PCA will try to fit a line that corss the mean point and \n",
    "has the largest spreadout in terms of points. \\\n",
    "The second component will be prependicular to the first component, corssing the mean point, \n",
    "and has the largest spreadout in its direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first component \n",
    "df.plot.scatter(\"A\", \"B\")\n",
    "\n",
    "plt.plot(mean_point[0], mean_point[1], marker=\"X\", markersize=20, color=\"red\")\n",
    "span = 6\n",
    "point2 = [span + mean_point[0], C[0][1] / C[0][0] * span + mean_point[1]]\n",
    "point3 = [-span + mean_point[0], C[0][1] / C[0][0] * (-span) + mean_point[1]]\n",
    "x = [point2[0], point3[0]]\n",
    "y = [point2[1], point3[1]]\n",
    "plt.plot(x, y, linestyle=\"-\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First column of W represents relative positions of points along the first component \\\n",
    "Second column of W represents relative positions of points along the second component \\\n",
    "and so on ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W.shape, C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"A\", \"B\"]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use W and C to reconstruct the original A & B columns\n",
    "pd.DataFrame((W @ C) + p.mean_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"A\", \"B\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only the first component to approximately reconstruct A & B columns\n",
    "# the first column of W (relative position of W along the first component) multiply the first row of C (the first component)\n",
    "pd.DataFrame(W[:, :1] @ C[:1, :] + p.mean_).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1.1, 1.9, 3.2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1, 2, 3])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a - b).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (a - b).var() / a.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the amount of variance explained by each components\n",
    "# the first component has largest explained variance\n",
    "# the second component has the second largest explained variance\n",
    "# and so on \n",
    "explained_variance = p.explained_variance_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance / explained_variance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained variance percentage wise\n",
    "p.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on two dependent columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCA()\n",
    "W = p.fit_transform(df[[\"A\", \"C\"]])\n",
    "C = p.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = p.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot A & C columns and the mean \n",
    "df.plot.scatter(\"A\", \"C\")\n",
    "mean_point = [mean[0],mean[1]]\n",
    "plt.plot(mean[0],mean[1], marker=\"X\", markersize=20, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first component\n",
    "df.plot.scatter(\"A\", \"C\")\n",
    "mean_point = [mean[0],mean[1]]\n",
    "plt.plot(mean_point[0], mean_point[1], marker=\"X\", markersize=20, color=\"red\")\n",
    "span = 6\n",
    "point2 = [span + mean_point[0], C[0][1] / C[0][0] * span + mean_point[1]]\n",
    "point3 = [-span + mean_point[0], C[0][1] / C[0][0] * (-span) + mean_point[1]]\n",
    "x = [point2[0], point3[0]]\n",
    "y = [point2[1], point3[1]]\n",
    "plt.plot(x, y, linestyle=\"-\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noted the first component is explianing 100% of the data\n",
    "# because C is two times of A\n",
    "# the first component is capturing the 2* relationship using its slope\n",
    "p.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can reconstruct A & C only using one component\n",
    "pd.DataFrame(W[:, :1] @ C[:1, :] + p.mean_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"A\", \"C\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCA()\n",
    "W = p.fit_transform(df)\n",
    "C = p.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four components for 4d data\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noted the first two components are explaining 100% of the data\n",
    "ev_ratio = p.explained_variance_ratio_\n",
    "ev_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can reconstruct the original dataframe only using the first two components\n",
    "pd.DataFrame(W[:, :2] @ C[:2, :] + p.mean_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative plot of explained variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumsum() compute the cumulative sum\n",
    "s = pd.Series(p.explained_variance_ratio_.cumsum(), index=range(1,5))\n",
    "ax = s.plot.line(ylim=0)\n",
    "ax.set_ylabel(\"Explained Variance\")\n",
    "ax.set_xlabel(\"Component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction on Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"pca\", PCA(2)), \n",
    "    # n_components parameter\n",
    "    # specify an int for number of components to use \n",
    "    # or a float indicates how much variance we want to explain (explained_variance_ratio_)\n",
    "    (\"km\", KMeans(2)),\n",
    "])\n",
    "\n",
    "pipe.fit(df) # fit PCA, transform using PCA, fit KMeans using output from PCA\n",
    "\n",
    "groups = pipe.predict(df) # transform using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 is white\n",
    "pd.DataFrame(pipe[\"pca\"].transform(df)).plot.scatter(x=0, y=1, c=groups, vmin=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lossy Compression\n",
    "\n",
    "Use PCA to extract the most important information and throw away the less important ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"bug.jpeg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging the color dimension to make it a bit more easy to handle\n",
    "img = img.mean(axis=2)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to explian 95% of the variance\n",
    "p = PCA(0.95)\n",
    "W = p.fit_transform(img)\n",
    "C = p.components_\n",
    "m = p.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = len(img.reshape(-1))\n",
    "original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_size = len(W.reshape(-1)) + len(C.reshape(-1)) + len(m.reshape(-1))\n",
    "compressed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression ratio\n",
    "original_size / compressed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W @ C + m, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savez saves numpy arrays into .npz format\n",
    "# use wb to write in binary format\n",
    "with open(\"img1.npz\", \"wb\") as f: \n",
    "    np.savez(f, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img2.npz\", \"wb\") as f: \n",
    "    np.savez(f, W, C, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"img2.npz\") as f: \n",
    "    W, C, m = f.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W @ C + m, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original plot is 33M vs. the compressed plot is 876K\n",
    "!ls -lh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
